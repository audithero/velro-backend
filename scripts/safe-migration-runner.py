#!/usr/bin/env python3
"""
üóÑÔ∏è Safe Database Migration Runner
Bulletproof migration execution with backup and validation
Usage: python scripts/safe-migration-runner.py [migration_file]
"""

import os
import sys
import json
import traceback
from datetime import datetime
from pathlib import Path
import psycopg2
import psycopg2.extras
from typing import Dict, List, Optional, Tuple
import hashlib
import subprocess

# Add the project root to Python path for imports
sys.path.append(str(Path(__file__).parent.parent))

try:
    from database import get_db_connection
    from config import DATABASE_URL
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Make sure you're running this from the project root directory")
    sys.exit(1)

class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    PURPLE = '\033[0;35m'
    CYAN = '\033[0;36m'
    NC = '\033[0m'  # No Color

class SafeMigrationRunner:
    def __init__(self, migration_file: str):
        self.migration_file = Path(migration_file)
        self.migration_name = self.migration_file.stem
        self.backup_id = f"pre-{self.migration_name}-{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.report = {
            'migration_file': str(self.migration_file),
            'migration_name': self.migration_name,
            'backup_id': self.backup_id,
            'started_at': datetime.now().isoformat(),
            'phases': {},
            'validation_results': {},
            'rollback_info': {},
            'success': False
        }
        
    def log(self, message: str, color: str = Colors.BLUE):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"{color}[{timestamp}]{Colors.NC} {message}")
        
    def success(self, message: str):
        self.log(f"‚úÖ {message}", Colors.GREEN)
        
    def warning(self, message: str):
        self.log(f"‚ö†Ô∏è {message}", Colors.YELLOW)
        
    def error(self, message: str):
        self.log(f"‚ùå {message}", Colors.RED)
        
    def emergency(self, message: str):
        self.log(f"üö® EMERGENCY: {message}", Colors.RED)

    def validate_migration_file(self) -> bool:
        """Validate migration file exists and is readable"""
        self.log("üîç Validating migration file...")
        
        if not self.migration_file.exists():
            self.error(f"Migration file not found: {self.migration_file}")
            return False
            
        if not self.migration_file.is_file():
            self.error(f"Path is not a file: {self.migration_file}")
            return False
            
        try:
            with open(self.migration_file, 'r') as f:
                content = f.read()
                if not content.strip():
                    self.error("Migration file is empty")
                    return False
                    
                # Basic SQL validation
                if 'CREATE TABLE' not in content and 'ALTER TABLE' not in content:
                    self.warning("Migration file doesn't contain typical DDL statements")
                    
        except Exception as e:
            self.error(f"Error reading migration file: {e}")
            return False
            
        self.success("Migration file validation passed")
        return True

    def create_backup_point(self) -> bool:
        """Create a logical backup point for rollback"""
        self.log("üíæ Creating database backup point...")
        
        try:
            # For Supabase/Railway, we rely on automatic backups
            # But we can document the backup point for reference
            self.report['backup_info'] = {
                'backup_id': self.backup_id,
                'created_at': datetime.now().isoformat(),
                'type': 'logical_point',
                'note': 'Supabase automatic backups available via dashboard'
            }
            
            self.success(f"Backup point created: {self.backup_id}")
            self.log("üìã Backup available via Supabase dashboard")
            return True
            
        except Exception as e:
            self.error(f"Failed to create backup point: {e}")
            return False

    def analyze_migration_content(self) -> Dict:
        """Analyze migration content for risk assessment"""
        self.log("üîç Analyzing migration content...")
        
        try:
            with open(self.migration_file, 'r') as f:
                content = f.read()
                
            analysis = {
                'tables_created': [],
                'tables_altered': [],
                'indexes_created': [],
                'policies_created': [],
                'functions_created': [],
                'risk_level': 'low',
                'estimated_duration': 'short'
            }
            
            lines = content.split('\n')
            for line in lines:
                line_clean = line.strip().upper()
                
                # Identify table operations
                if line_clean.startswith('CREATE TABLE'):
                    table_name = line_clean.split()[2]
                    analysis['tables_created'].append(table_name)
                elif line_clean.startswith('ALTER TABLE'):
                    table_name = line_clean.split()[2]
                    if table_name not in analysis['tables_altered']:
                        analysis['tables_altered'].append(table_name)
                        
                # Identify indexes
                elif line_clean.startswith('CREATE INDEX') or line_clean.startswith('CREATE UNIQUE INDEX'):
                    index_parts = line_clean.split()
                    if 'INDEX' in index_parts:
                        idx = index_parts.index('INDEX') + 1
                        if idx < len(index_parts):
                            analysis['indexes_created'].append(index_parts[idx])
                            
                # Identify RLS policies
                elif line_clean.startswith('CREATE POLICY'):
                    policy_parts = line_clean.split('"')
                    if len(policy_parts) > 1:
                        analysis['policies_created'].append(policy_parts[1])
                        
                # Identify functions
                elif line_clean.startswith('CREATE OR REPLACE FUNCTION'):
                    func_parts = line_clean.split()
                    if len(func_parts) > 4:
                        analysis['functions_created'].append(func_parts[4].split('(')[0])
            
            # Risk assessment
            total_operations = (len(analysis['tables_created']) + 
                              len(analysis['tables_altered']) + 
                              len(analysis['indexes_created']))
            
            if total_operations > 20:
                analysis['risk_level'] = 'high'
                analysis['estimated_duration'] = 'long'
            elif total_operations > 10:
                analysis['risk_level'] = 'medium'
                analysis['estimated_duration'] = 'medium'
                
            self.report['migration_analysis'] = analysis
            
            # Log analysis results
            self.success("Migration content analyzed")
            self.log(f"üìä Tables to create: {len(analysis['tables_created'])}")
            self.log(f"üìä Tables to alter: {len(analysis['tables_altered'])}")
            self.log(f"üìä Indexes to create: {len(analysis['indexes_created'])}")
            self.log(f"üìä RLS policies: {len(analysis['policies_created'])}")
            self.log(f"üìä Risk level: {analysis['risk_level']}")
            
            return analysis
            
        except Exception as e:
            self.error(f"Failed to analyze migration content: {e}")
            return {}

    def dry_run_migration(self) -> bool:
        """Perform a dry run validation without applying changes"""
        self.log("üß™ Performing migration dry run...")
        
        try:
            with open(self.migration_file, 'r') as f:
                migration_sql = f.read()
                
            # Connect to database
            conn = get_db_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            
            # Begin transaction (will be rolled back)
            cursor.execute("BEGIN;")
            
            dry_run_results = {
                'syntax_valid': False,
                'tables_would_create': [],
                'conflicts_detected': [],
                'dependencies_satisfied': True
            }
            
            try:
                # Test SQL syntax by parsing (not executing)
                # Split migration into individual statements
                statements = [stmt.strip() for stmt in migration_sql.split(';') if stmt.strip()]
                
                for i, statement in enumerate(statements):
                    if statement.upper().startswith(('CREATE TABLE', 'ALTER TABLE')):
                        # For DDL statements, we can prepare them to check syntax
                        try:
                            cursor.execute(f"EXPLAIN {statement}")
                            dry_run_results['syntax_valid'] = True
                        except psycopg2.Error:
                            # For CREATE statements, EXPLAIN won't work
                            # Just check if the statement is parseable
                            pass
                
                # Check for existing tables that might conflict
                analysis = self.report.get('migration_analysis', {})
                for table in analysis.get('tables_created', []):
                    cursor.execute("""
                        SELECT EXISTS (
                            SELECT 1 FROM information_schema.tables 
                            WHERE table_name = %s
                        )
                    """, (table.lower().replace('"', ''),))
                    
                    exists = cursor.fetchone()[0]
                    if exists:
                        dry_run_results['conflicts_detected'].append(f"Table {table} already exists")
                    else:
                        dry_run_results['tables_would_create'].append(table)
                
                dry_run_results['syntax_valid'] = True
                
            except psycopg2.Error as e:
                self.error(f"SQL syntax error detected: {e}")
                dry_run_results['syntax_valid'] = False
                dry_run_results['error'] = str(e)
                
            finally:
                # Always rollback the dry run transaction
                cursor.execute("ROLLBACK;")
                cursor.close()
                conn.close()
            
            self.report['dry_run_results'] = dry_run_results
            
            if dry_run_results['syntax_valid']:
                self.success("Dry run completed successfully")
                if dry_run_results['conflicts_detected']:
                    for conflict in dry_run_results['conflicts_detected']:
                        self.warning(f"Conflict detected: {conflict}")
                return True
            else:
                self.error("Dry run failed - SQL syntax errors detected")
                return False
                
        except Exception as e:
            self.error(f"Dry run failed with exception: {e}")
            traceback.print_exc()
            return False

    def execute_migration(self) -> bool:
        """Execute the migration with comprehensive error handling"""
        self.log("‚ö° Executing migration...")
        
        try:
            with open(self.migration_file, 'r') as f:
                migration_sql = f.read()
                
            # Connect to database
            conn = get_db_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            
            execution_start = datetime.now()
            
            try:
                # Execute migration in a transaction
                cursor.execute("BEGIN;")
                
                # Execute the migration SQL
                cursor.execute(migration_sql)
                
                # Commit the transaction
                cursor.execute("COMMIT;")
                
                execution_end = datetime.now()
                duration = (execution_end - execution_start).total_seconds()
                
                self.report['execution'] = {
                    'started_at': execution_start.isoformat(),
                    'completed_at': execution_end.isoformat(),
                    'duration_seconds': duration,
                    'success': True
                }
                
                self.success(f"Migration executed successfully in {duration:.2f} seconds")
                return True
                
            except psycopg2.Error as e:
                # Rollback on error
                cursor.execute("ROLLBACK;")
                
                self.error(f"Migration execution failed: {e}")
                self.report['execution'] = {
                    'started_at': execution_start.isoformat(),
                    'failed_at': datetime.now().isoformat(),
                    'error': str(e),
                    'success': False
                }
                return False
                
            finally:
                cursor.close()
                conn.close()
                
        except Exception as e:
            self.error(f"Migration execution failed with exception: {e}")
            traceback.print_exc()
            return False

    def validate_migration_results(self) -> bool:
        """Validate that migration was applied correctly"""
        self.log("üß™ Validating migration results...")
        
        try:
            conn = get_db_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            
            validation_results = {
                'tables_created': [],
                'indexes_created': [],
                'policies_created': [],
                'triggers_created': [],
                'all_validations_passed': True
            }
            
            analysis = self.report.get('migration_analysis', {})
            
            # Validate tables were created
            for table in analysis.get('tables_created', []):
                table_clean = table.lower().replace('"', '')
                cursor.execute("""
                    SELECT EXISTS (
                        SELECT 1 FROM information_schema.tables 
                        WHERE table_name = %s
                    )
                """, (table_clean,))
                
                exists = cursor.fetchone()[0]
                if exists:
                    validation_results['tables_created'].append(table_clean)
                    self.success(f"Table verified: {table_clean}")
                else:
                    self.error(f"Table not found: {table_clean}")
                    validation_results['all_validations_passed'] = False
            
            # Validate indexes were created
            expected_indexes = analysis.get('indexes_created', [])
            if expected_indexes:
                cursor.execute("""
                    SELECT indexname FROM pg_indexes 
                    WHERE schemaname = 'public'
                    AND indexname LIKE 'idx_%'
                """)
                actual_indexes = [row[0] for row in cursor.fetchall()]
                validation_results['indexes_created'] = actual_indexes
                self.success(f"Indexes created: {len(actual_indexes)}")
            
            # Validate RLS policies
            if analysis.get('policies_created'):
                cursor.execute("""
                    SELECT schemaname, tablename, policyname
                    FROM pg_policies 
                    WHERE schemaname = 'public'
                """)
                policies = cursor.fetchall()
                validation_results['policies_created'] = [p[2] for p in policies]
                self.success(f"RLS policies active: {len(policies)}")
            
            # Validate triggers
            cursor.execute("""
                SELECT trigger_name, event_object_table
                FROM information_schema.triggers 
                WHERE trigger_schema = 'public'
            """)
            triggers = cursor.fetchall()
            validation_results['triggers_created'] = [t[0] for t in triggers]
            self.success(f"Triggers active: {len(triggers)}")
            
            cursor.close()
            conn.close()
            
            self.report['validation_results'] = validation_results
            
            if validation_results['all_validations_passed']:
                self.success("All migration validations passed")
                return True
            else:
                self.error("Some migration validations failed")
                return False
                
        except Exception as e:
            self.error(f"Validation failed with exception: {e}")
            traceback.print_exc()
            return False

    def generate_rollback_script(self) -> str:
        """Generate SQL rollback script based on migration content"""
        self.log("üìú Generating rollback script...")
        
        try:
            analysis = self.report.get('migration_analysis', {})
            rollback_script = f"""-- Rollback script for migration: {self.migration_name}
-- Generated at: {datetime.now().isoformat()}
-- Backup ID: {self.backup_id}

-- WARNING: This will remove all changes made by the migration
-- Make sure you have a database backup before proceeding!

BEGIN;

-- Drop tables in reverse dependency order
"""
            
            # Add table drops in reverse order
            tables_to_drop = analysis.get('tables_created', [])
            tables_to_drop.reverse()  # Drop in reverse order to handle dependencies
            
            for table in tables_to_drop:
                rollback_script += f"DROP TABLE IF EXISTS {table} CASCADE;\n"
                
            rollback_script += """
-- Remove any added columns (add specific ALTER TABLE statements here)
-- Example: ALTER TABLE existing_table DROP COLUMN IF EXISTS new_column;

-- Restore original constraints if they were modified
-- Add specific constraint restoration here

COMMIT;

-- Instructions for manual rollback steps:
-- 1. Restore from Supabase backup if full rollback needed
-- 2. Check application logs for any data inconsistencies
-- 3. Verify all foreign key relationships are intact
-- 4. Test critical application functionality
"""
            
            # Save rollback script
            rollback_file = f"rollback_{self.migration_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
            rollback_path = Path(__file__).parent.parent / "migrations" / rollback_file
            
            with open(rollback_path, 'w') as f:
                f.write(rollback_script)
                
            self.report['rollback_info'] = {
                'rollback_script_path': str(rollback_path),
                'backup_id': self.backup_id,
                'generated_at': datetime.now().isoformat()
            }
            
            self.success(f"Rollback script generated: {rollback_file}")
            return str(rollback_path)
            
        except Exception as e:
            self.error(f"Failed to generate rollback script: {e}")
            return ""

    def generate_final_report(self) -> str:
        """Generate comprehensive migration report"""
        self.log("üìä Generating migration report...")
        
        self.report['completed_at'] = datetime.now().isoformat()
        
        # Create report file
        report_file = f"migration_report_{self.migration_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        report_path = Path(__file__).parent.parent / "migration-reports" / report_file
        
        # Create reports directory if it doesn't exist
        report_path.parent.mkdir(exist_ok=True)
        
        # Save detailed JSON report
        with open(report_path, 'w') as f:
            json.dump(self.report, f, indent=2, default=str)
            
        # Create human-readable markdown report
        md_report_file = report_file.replace('.json', '.md')
        md_report_path = report_path.with_suffix('.md')
        
        analysis = self.report.get('migration_analysis', {})
        validation = self.report.get('validation_results', {})
        execution = self.report.get('execution', {})
        
        md_content = f"""# Migration Report: {self.migration_name}

**Date**: {self.report['started_at']}
**Status**: {'‚úÖ SUCCESS' if self.report['success'] else '‚ùå FAILED'}
**Migration File**: {self.migration_file}

## Migration Summary

### Tables Created ({len(analysis.get('tables_created', []))})
{chr(10).join(f'- {table}' for table in analysis.get('tables_created', []))}

### Indexes Created ({len(analysis.get('indexes_created', []))})
{chr(10).join(f'- {idx}' for idx in analysis.get('indexes_created', []))}

### RLS Policies Created ({len(analysis.get('policies_created', []))})
{chr(10).join(f'- {policy}' for policy in analysis.get('policies_created', []))}

## Execution Details

- **Duration**: {execution.get('duration_seconds', 'N/A')} seconds
- **Risk Level**: {analysis.get('risk_level', 'unknown')}
- **Backup ID**: {self.backup_id}

## Validation Results

- **Tables Validated**: {len(validation.get('tables_created', []))}
- **Indexes Validated**: {len(validation.get('indexes_created', []))}
- **RLS Policies Active**: {len(validation.get('policies_created', []))}
- **Triggers Active**: {len(validation.get('triggers_created', []))}

## Rollback Information

**Backup ID**: {self.backup_id}
**Rollback Script**: {self.report.get('rollback_info', {}).get('rollback_script_path', 'Not generated')}

### Emergency Rollback Steps:
1. Access Supabase Dashboard
2. Navigate to Database > Backups
3. Restore backup: {self.backup_id}
4. Or execute generated rollback SQL script

## Files Generated
- **Detailed Report**: {report_file}
- **Rollback Script**: {self.report.get('rollback_info', {}).get('rollback_script_path', 'Not generated')}

---
*Generated by Safe Migration Runner*
"""
        
        with open(md_report_path, 'w') as f:
            f.write(md_content)
            
        self.success(f"Migration reports generated:")
        self.log(f"üìÑ JSON Report: {report_file}")
        self.log(f"üìÑ Markdown Report: {md_report_file}")
        
        return str(report_path)

    def run_migration(self) -> bool:
        """Execute complete migration process with safety checks"""
        print(f"\n{Colors.CYAN}üóÑÔ∏è ===============================================")
        print("üöÄ SAFE DATABASE MIGRATION RUNNER")
        print("üóÑÔ∏è ===============================================")
        print(f"{Colors.NC}")
        print(f"Migration: {self.migration_file}")
        print(f"Backup ID: {self.backup_id}")
        print(f"Started: {datetime.now()}")
        print("")
        
        try:
            # Phase 1: Validation
            self.log("üß™ Phase 1: Pre-migration validation")
            if not self.validate_migration_file():
                return False
                
            # Phase 2: Analysis
            self.log("üîç Phase 2: Migration analysis")
            if not self.analyze_migration_content():
                self.warning("Migration analysis incomplete, continuing...")
                
            # Phase 3: Backup
            self.log("üíæ Phase 3: Backup creation")
            if not self.create_backup_point():
                self.warning("Backup creation incomplete, continuing...")
                
            # Phase 4: Dry run
            self.log("üß™ Phase 4: Dry run validation")
            if not self.dry_run_migration():
                self.error("Dry run failed - stopping migration")
                return False
                
            # Confirmation prompt (skip in CI)
            if os.isatty(sys.stdin.fileno()) and not os.environ.get('CI'):
                print(f"\n{Colors.YELLOW}‚ö†Ô∏è Ready to execute migration on production database{Colors.NC}")
                print(f"Migration: {self.migration_name}")
                print(f"Backup ID: {self.backup_id}")
                confirmation = input("Continue? (y/N): ")
                if confirmation.lower() != 'y':
                    self.log("Migration cancelled by user")
                    return False
                    
            # Phase 5: Execution
            self.log("‚ö° Phase 5: Migration execution")
            if not self.execute_migration():
                self.error("Migration execution failed")
                self.generate_rollback_script()
                return False
                
            # Phase 6: Validation
            self.log("üß™ Phase 6: Post-migration validation")
            if not self.validate_migration_results():
                self.error("Migration validation failed")
                self.generate_rollback_script()
                return False
                
            # Phase 7: Reporting
            self.log("üìä Phase 7: Report generation")
            self.generate_rollback_script()
            self.generate_final_report()
            
            self.report['success'] = True
            
            print(f"\n{Colors.GREEN}üéâ MIGRATION COMPLETED SUCCESSFULLY{Colors.NC}")
            print(f"‚úÖ Migration: {self.migration_name}")
            print(f"‚úÖ Backup ID: {self.backup_id}")
            print(f"‚úÖ Duration: {datetime.now() - datetime.fromisoformat(self.report['started_at'])}")
            print(f"‚úÖ All validations passed")
            print("")
            print("üöÄ SYSTEM READY FOR DEPLOYMENT")
            
            return True
            
        except Exception as e:
            self.emergency(f"Critical error during migration: {e}")
            traceback.print_exc()
            self.generate_rollback_script()
            self.generate_final_report()
            return False

def main():
    if len(sys.argv) != 2:
        print("Usage: python scripts/safe-migration-runner.py <migration_file>")
        print("")
        print("Examples:")
        print("  python scripts/safe-migration-runner.py migrations/011_team_collaboration_foundation.sql")
        print("  python scripts/safe-migration-runner.py migrations/012_next_migration.sql")
        sys.exit(1)
        
    migration_file = sys.argv[1]
    
    runner = SafeMigrationRunner(migration_file)
    success = runner.run_migration()
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()